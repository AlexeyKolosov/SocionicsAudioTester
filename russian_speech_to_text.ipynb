{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAY SOMETHING\n",
      "TIME OVER, THANKS\n",
      "TEXT:  сегодня пошёл снег и я забыл что было вчера\n"
     ]
    }
   ],
   "source": [
    "from nltk.util import ngrams\n",
    "import speech_recognition as sr\n",
    "import fasttext\n",
    "r = sr.Recognizer()\n",
    "with sr.Microphone() as source:\n",
    "    print(\"SAY SOMETHING\")\n",
    "    audio = r.listen(source)\n",
    "    print(\"TIME OVER, THANKS\")\n",
    "try:\n",
    "    text = r.recognize_google(audio, language = 'ru-RU')\n",
    "    print(\"TEXT: \", text)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "words_from_text = text.lower().split()\n",
    "LABELS = [\"WHITE_ETHICS\", \"BLACK_ETHICS\", \n",
    "          \"WHITE_LOGICS\",\"BLACK_LOGICS\",\n",
    "          \"WHITE_SENSORICS\",\"BLACK_SENSORICS\",\n",
    "          \"WHITE_INTUITION\",\"BLACK_INTUITION\"]\n",
    "\n",
    "WHITE_ETHICS_WORD_LIST = []\n",
    "BLACK_ETHICS_WORD_LIST = []\n",
    "WHITE_LOGICS_WORD_LIST = []\n",
    "BLACK_LOGICS_WORD_LIST = []\n",
    "WHITE_SENSORICS_WORD_LIST = []\n",
    "BLACK_SENSORICS_WORD_LIST = []\n",
    "WHITE_INTUITION_WORD_LIST = []\n",
    "BLACK_INTUITION_WORD_LIST = []\n",
    "\n",
    "for label, word_list in zip(LABELS, [WHITE_ETHICS_WORD_LIST, \n",
    "                                     BLACK_ETHICS_WORD_LIST, \n",
    "                                     WHITE_LOGICS_WORD_LIST, \n",
    "                                     BLACK_LOGICS_WORD_LIST, \n",
    "                                     WHITE_SENSORICS_WORD_LIST, \n",
    "                                     BLACK_SENSORICS_WORD_LIST, \n",
    "                                     WHITE_INTUITION_WORD_LIST, \n",
    "                                     BLACK_INTUITION_WORD_LIST]):\n",
    "    with open(label + \"_WORD_LIST.txt\", \"r\", encoding = 'utf-16') as file:\n",
    "        word_list = file.readlines()\n",
    "    for i in range(len(word_list)):\n",
    "        word_list[i] = word_list[i].replace(\"\\n\", \"\").lower()\n",
    "    file.close()\n",
    "WHITE_ETHICS_WORD_LIST = list(set(WHITE_ETHICS_WORD_LIST))\n",
    "BLACK_ETHICS_WORD_LIST = list(set(BLACK_ETHICS_WORD_LIST))\n",
    "WHITE_LOGICS_WORD_LIST = list(set(WHITE_LOGICS_WORD_LIST))\n",
    "BLACK_LOGICS_WORD_LIST = list(set(BLACK_LOGICS_WORD_LIST))\n",
    "WHITE_SENSORICS_WORD_LIST = list(set(WHITE_SENSORICS_WORD_LIST))\n",
    "BLACK_SENSORICS_WORD_LIST = list(set(BLACK_SENSORICS_WORD_LIST))\n",
    "WHITE_INTUITION_WORD_LIST = list(set(WHITE_INTUITION_WORD_LIST))\n",
    "BLACK_INTUITION_WORD_LIST = list(set(BLACK_INTUITION_WORD_LIST))\n",
    "\n",
    "#==========================================================\n",
    "# # word lists intersections check:\n",
    "# for word_list_A in [WHITE_ETHICS_WORD_LIST, \n",
    "#                   BLACK_ETHICS_WORD_LIST, \n",
    "#                   WHITE_LOGICS_WORD_LIST, \n",
    "#                   BLACK_LOGICS_WORD_LIST, \n",
    "#                   WHITE_SENSORICS_WORD_LIST, \n",
    "#                   BLACK_SENSORICS_WORD_LIST, \n",
    "#                   WHITE_INTUITION_WORD_LIST, \n",
    "#                   BLACK_INTUITION_WORD_LIST]:\n",
    "#     for word_list_B in\n",
    "#==========================================================\n",
    "    \n",
    "\n",
    "WHITE_ETHICS = 0\n",
    "BLACK_ETHICS = 0\n",
    "WHITE_LOGICS = 0\n",
    "BLACK_LOGICS = 0\n",
    "WHITE_SENSORICS = 0\n",
    "BLACK_SENSORICS = 0\n",
    "WHITE_INTUITION = 0\n",
    "BLACK_INTUITION = 0\n",
    "    \n",
    "two_grams = []\n",
    "for two_gram in list(ngrams(words_from_text, 2)):\n",
    "    two_grams.append(\" \".join(two_gram))\n",
    "    \n",
    "for word in words_from_text:\n",
    "    if word in WHITE_ETHICS_WORD_LIST:\n",
    "        WHITE_ETHICS = WHITE_ETHICS + 1\n",
    "    elif word in BLACK_ETHICS_WORD_LIST:\n",
    "        BLACK_ETHICS = BLACK_ETHICS + 1\n",
    "    elif word in WHITE_LOGICS_WORD_LIST:\n",
    "        WHITE_LOGICS = WHITE_LOGICS + 1\n",
    "    elif word in BLACK_LOGICS_WORD_LIST:\n",
    "        BLACK_LOGICS = BLACK_LOGICS + 1\n",
    "    elif word in WHITE_SENSORICS_WORD_LIST:\n",
    "        WHITE_SENSORICS = WHITE_SENSORICS + 1\n",
    "    elif word in BLACK_SENSORICS_WORD_LIST:\n",
    "        BLACK_SENSORICS = BLACK_SENSORICS + 1\n",
    "    elif word in WHITE_INTUITION_WORD_LIST:\n",
    "        WHITE_INTUITION = WHITE_INTUITION + 1\n",
    "    elif word in BLACK_INTUITION_WORD_LIST:\n",
    "        BLACK_INTUITION = BLACK_INTUITION + 1\n",
    "for two_gram in two_grams:\n",
    "    if two_gram in WHITE_ETHICS_WORD_LIST:\n",
    "        WHITE_ETHICS = WHITE_ETHICS + 1\n",
    "    elif two_gram in BLACK_ETHICS_WORD_LIST:\n",
    "        BLACK_ETHICS = BLACK_ETHICS + 1\n",
    "    elif two_gram in WHITE_LOGICS_WORD_LIST:\n",
    "        WHITE_LOGICS = WHITE_LOGICS + 1\n",
    "    elif two_gram in BLACK_LOGICS_WORD_LIST:\n",
    "        BLACK_LOGICS = BLACK_LOGICS + 1\n",
    "    elif two_gram in WHITE_SENSORICS_WORD_LIST:\n",
    "        WHITE_SENSORICS = WHITE_SENSORICS + 1\n",
    "    elif two_gram in BLACK_SENSORICS_WORD_LIST:\n",
    "        BLACK_SENSORICS = BLACK_SENSORICS + 1\n",
    "    elif two_gram in WHITE_INTUITION_WORD_LIST:\n",
    "        WHITE_INTUITION = WHITE_INTUITION + 1\n",
    "    elif two_gram in BLACK_INTUITION_WORD_LIST:\n",
    "        BLACK_INTUITION = BLACK_INTUITION + 1 \n",
    "\n",
    "# max({WHITE_ETHICS:\"WHITE_ETHICS\",BLACK_ETHICS:\"BLACK_ETHICS\"})\n",
    "# max({WHITE_LOGICS:\"WHITE_LOGICS\",BLACK_LOGICS:\"BLACK_LOGICS\"})\n",
    "# max({WHITE_SENSORICS:\"WHITE_SENSORICS\",BLACK_SENSORICS:\"BLACK_SENSORICS\"})\n",
    "# max({WHITE_INTUITION:\"WHITE_INTUITION\",BLACK_INTUITION:\"BLACK_INTUITION\"})\n",
    "\n",
    "\n",
    "values = [WHITE_ETHICS, \n",
    "          BLACK_ETHICS, \n",
    "          WHITE_LOGICS,\n",
    "          BLACK_LOGICS,\n",
    "          WHITE_SENSORICS,\n",
    "          BLACK_SENSORICS,\n",
    "          WHITE_INTUITION, \n",
    "          BLACK_INTUITION]\n",
    "\n",
    "values_sorted, labels_sorted = zip(*sorted(zip(values, LABELS), reverse=True))\n",
    "print(\"your strong sides are \", labels_sorted[:2])\n",
    "\n",
    "def train_socionics_fasttext_model(save_model = True):\n",
    "    with open('socionics_fasttext_train_data.txt', 'w', encoding='utf-16') as file:\n",
    "        for label, word_list in zip(LABELS, [WHITE_ETHICS_WORD_LIST, \n",
    "                                             BLACK_ETHICS_WORD_LIST, \n",
    "                                             WHITE_LOGICS_WORD_LIST, \n",
    "                                             BLACK_LOGICS_WORD_LIST, \n",
    "                                             WHITE_SENSORICS_WORD_LIST, \n",
    "                                             BLACK_SENSORICS_WORD_LIST, \n",
    "                                             WHITE_INTUITION_WORD_LIST, \n",
    "                                             BLACK_INTUITION_WORD_LIST]):\n",
    "            for i in range(len(word_list):\n",
    "                file.write('{} {}\\n'.format(word_list[i], f\"__{label}__\"))\n",
    "    \n",
    "    model = fasttext.train_supervised(verbose=0, input='socionics_fasttext_train_data.txt', thread=1, minCount=1, wordNgrams=1, lr=0.1, epoch=5, loss='softmax')\n",
    "    if save_model is True:\n",
    "        model.save_model(\"socionics_fasttext_model.ckpt\")\n",
    "\n",
    "model = fasttext.load_model(\"socionics_fasttext_model.ckpt\")\n",
    "                           \n",
    "                           \n",
    "def predict_all(model):\n",
    "    phrases = words_from_text + two_grams\n",
    "    for phrase in phrases:    \n",
    "        # to do lemmatizer before predict\n",
    "        data = model.predict(phrase, k=1)\n",
    "        predicted_label = str(data[0][0].replace('__label__', ''))\n",
    "        if predicted_label == 'WHITE_ETHICS':\n",
    "            WHITE_ETHICS = WHITE_ETHICS + 1\n",
    "        elif predicted_label == 'BLACK_ETHICS':\n",
    "            BLACK_ETHICS = BLACK_ETHICS + 1\n",
    "        elif predicted_label == 'WHITE_LOGICS':\n",
    "            WHITE_LOGICS = WHITE_LOGICS + 1\n",
    "        elif predicted_label == 'BLACK_LOGICS':\n",
    "            BLACK_LOGICS = BLACK_LOGICS + 1\n",
    "        elif predicted_label == 'WHITE_SENSORICS':\n",
    "            WHITE_SENSORICS = WHITE_SENSORICS + 1\n",
    "        elif predicted_label == 'BLACK_SENSORICS':\n",
    "            BLACK_SENSORICS = BLACK_SENSORICS + 1\n",
    "        elif predicted_label == 'WHITE_INTUITION':\n",
    "            WHITE_INTUITION = WHITE_INTUITION + 1\n",
    "        elif predicted_label == 'BLACK_INTUITION':\n",
    "            BLACK_INTUITION = BLACK_INTUITION + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
